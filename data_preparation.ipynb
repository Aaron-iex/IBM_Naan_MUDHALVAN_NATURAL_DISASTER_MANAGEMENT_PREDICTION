{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5603835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f2b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setup ---\n",
      "Looking for CSV at: data\\disasterIND.csv\n",
      "Output training data will be saved to: data\\train.jsonl\n",
      "Output validation data will be saved to: data\\validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random # For shuffling and splitting data\n",
    "from IPython.display import display # For better DataFrame display in notebooks\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = \"data\" # Ensure this folder exists in your project root\n",
    "# --- !!! IMPORTANT: Place your disasterIND.csv file inside the 'data' folder !!! ---\n",
    "CSV_FILE_PATH = os.path.join(DATA_DIR, \"disasterIND.csv\") \n",
    "OUTPUT_TRAIN_FILE = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "OUTPUT_VALID_FILE = os.path.join(DATA_DIR, \"validation.jsonl\")\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"--- Setup ---\")\n",
    "print(f\"Looking for CSV at: {CSV_FILE_PATH}\")\n",
    "print(f\"Output training data will be saved to: {OUTPUT_TRAIN_FILE}\")\n",
    "print(f\"Output validation data will be saved to: {OUTPUT_VALID_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83772b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading CSV Dataset ---\n",
      "Successfully loaded data\\disasterIND.csv. Shape: (783, 46)\n",
      "\n",
      "Columns: ['DisNo.', 'Historic', 'Classification Key', 'Disaster Group', 'Disaster Subgroup', 'Disaster Type', 'Disaster Subtype', 'External IDs', 'Event Name', 'ISO', 'Country', 'Subregion', 'Region', 'Location', 'Origin', 'Associated Types', 'OFDA/BHA Response', 'Appeal', 'Declaration', \"AID Contribution ('000 US$)\", 'Magnitude', 'Magnitude Scale', 'Latitude', 'Longitude', 'River Basin', 'Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month', 'End Day', 'Total Deaths', 'No. Injured', 'No. Affected', 'No. Homeless', 'Total Affected', \"Reconstruction Costs ('000 US$)\", \"Reconstruction Costs, Adjusted ('000 US$)\", \"Insured Damage ('000 US$)\", \"Insured Damage, Adjusted ('000 US$)\", \"Total Damage ('000 US$)\", \"Total Damage, Adjusted ('000 US$)\", 'CPI', 'Admin Units', 'Entry Date', 'Last Update']\n",
      "\n",
      "Sample Data (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DisNo.</th>\n",
       "      <th>Historic</th>\n",
       "      <th>Classification Key</th>\n",
       "      <th>Disaster Group</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>External IDs</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>ISO</th>\n",
       "      <th>...</th>\n",
       "      <th>Reconstruction Costs ('000 US$)</th>\n",
       "      <th>Reconstruction Costs, Adjusted ('000 US$)</th>\n",
       "      <th>Insured Damage ('000 US$)</th>\n",
       "      <th>Insured Damage, Adjusted ('000 US$)</th>\n",
       "      <th>Total Damage ('000 US$)</th>\n",
       "      <th>Total Damage, Adjusted ('000 US$)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Admin Units</th>\n",
       "      <th>Entry Date</th>\n",
       "      <th>Last Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-cli-dro-dro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.730451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1905-0003-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-geo-ear-gro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>847777.0</td>\n",
       "      <td>2.948887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1907-0001-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-bio-epi-bac</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Biological</td>\n",
       "      <td>Epidemic</td>\n",
       "      <td>Bacterial disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bubonic</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.058105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916-0004-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-met-sto-tro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.576717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920-0001-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-bio-epi-bac</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Biological</td>\n",
       "      <td>Epidemic</td>\n",
       "      <td>Bacterial disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bubonic</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.562784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DisNo. Historic Classification Key Disaster Group Disaster Subgroup  \\\n",
       "0  1900-9001-IND      Yes    nat-cli-dro-dro        Natural    Climatological   \n",
       "1  1905-0003-IND      Yes    nat-geo-ear-gro        Natural       Geophysical   \n",
       "2  1907-0001-IND      Yes    nat-bio-epi-bac        Natural        Biological   \n",
       "3  1916-0004-IND      Yes    nat-met-sto-tro        Natural    Meteorological   \n",
       "4  1920-0001-IND      Yes    nat-bio-epi-bac        Natural        Biological   \n",
       "\n",
       "  Disaster Type   Disaster Subtype External IDs Event Name  ISO  ...  \\\n",
       "0       Drought            Drought          NaN        NaN  IND  ...   \n",
       "1    Earthquake    Ground movement          NaN        NaN  IND  ...   \n",
       "2      Epidemic  Bacterial disease          NaN    Bubonic  IND  ...   \n",
       "3         Storm   Tropical cyclone          NaN        NaN  IND  ...   \n",
       "4      Epidemic  Bacterial disease          NaN    Bubonic  IND  ...   \n",
       "\n",
       "  Reconstruction Costs ('000 US$) Reconstruction Costs, Adjusted ('000 US$)  \\\n",
       "0                             NaN                                       NaN   \n",
       "1                             NaN                                       NaN   \n",
       "2                             NaN                                       NaN   \n",
       "3                             NaN                                       NaN   \n",
       "4                             NaN                                       NaN   \n",
       "\n",
       "  Insured Damage ('000 US$) Insured Damage, Adjusted ('000 US$)  \\\n",
       "0                       NaN                                 NaN   \n",
       "1                       NaN                                 NaN   \n",
       "2                       NaN                                 NaN   \n",
       "3                       NaN                                 NaN   \n",
       "4                       NaN                                 NaN   \n",
       "\n",
       "  Total Damage ('000 US$) Total Damage, Adjusted ('000 US$)       CPI  \\\n",
       "0                     NaN                               NaN  2.730451   \n",
       "1                 25000.0                          847777.0  2.948887   \n",
       "2                     NaN                               NaN  3.058105   \n",
       "3                     NaN                               NaN  3.576717   \n",
       "4                     NaN                               NaN  6.562784   \n",
       "\n",
       "  Admin Units  Entry Date  Last Update  \n",
       "0         NaN  2006-12-01   2023-09-25  \n",
       "1         NaN  2003-07-01   2023-09-25  \n",
       "2         NaN  2003-07-01   2023-09-25  \n",
       "3         NaN  2003-07-01   2023-09-25  \n",
       "4         NaN  2003-07-01   2023-09-25  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\\n--- Loading CSV Dataset ---\")\n",
    "try:\n",
    "    # Specify encoding, check common ones if utf-8 fails (e.g., 'latin1', 'iso-8859-1')\n",
    "    df_disasters = pd.read_csv(CSV_FILE_PATH, encoding='utf-8') \n",
    "    print(f\"Successfully loaded {CSV_FILE_PATH}. Shape: {df_disasters.shape}\")\n",
    "    print(\"\\nColumns:\", df_disasters.columns.tolist())\n",
    "    print(\"\\nSample Data (first 5 rows):\")\n",
    "    display(df_disasters.head()) \n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: CSV file not found at {CSV_FILE_PATH}. Please download it from Kaggle and place it in the '{DATA_DIR}' folder.\")\n",
    "    raise SystemExit(\"Stopping: CSV file required.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    raise SystemExit(f\"Stopping: Error loading CSV - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23830ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exploring and Filtering Data ---\n",
      "\n",
      "Exploring Disaster Types:\n",
      "Disaster Type\n",
      "Flood                          325\n",
      "Storm                          214\n",
      "Epidemic                        69\n",
      "Extreme temperature             64\n",
      "Mass movement (wet)             58\n",
      "Earthquake                      27\n",
      "Drought                         16\n",
      "Wildfire                         4\n",
      "Glacial lake outburst flood      3\n",
      "Mass movement (dry)              2\n",
      "Infestation                      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Handling missing values (filling with 'Unknown')...\n",
      "Warning: Column 'Total Damages' not found in CSV during fillna.\n",
      "\n",
      "Filtered down to 586 relevant events.\n",
      "\n",
      "Sample Filtered Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DisNo.</th>\n",
       "      <th>Historic</th>\n",
       "      <th>Classification Key</th>\n",
       "      <th>Disaster Group</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>External IDs</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>ISO</th>\n",
       "      <th>...</th>\n",
       "      <th>Reconstruction Costs ('000 US$)</th>\n",
       "      <th>Reconstruction Costs, Adjusted ('000 US$)</th>\n",
       "      <th>Insured Damage ('000 US$)</th>\n",
       "      <th>Insured Damage, Adjusted ('000 US$)</th>\n",
       "      <th>Total Damage ('000 US$)</th>\n",
       "      <th>Total Damage, Adjusted ('000 US$)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Admin Units</th>\n",
       "      <th>Entry Date</th>\n",
       "      <th>Last Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-cli-dro-dro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.730451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1905-0003-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-geo-ear-gro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>847777.0</td>\n",
       "      <td>2.948887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916-0004-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-met-sto-tro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.576717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1924-0003-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-met-sto-tro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.611180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1925-0004-IND</td>\n",
       "      <td>Yes</td>\n",
       "      <td>nat-met-sto-tro</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.742436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DisNo. Historic Classification Key Disaster Group Disaster Subgroup  \\\n",
       "0  1900-9001-IND      Yes    nat-cli-dro-dro        Natural    Climatological   \n",
       "1  1905-0003-IND      Yes    nat-geo-ear-gro        Natural       Geophysical   \n",
       "3  1916-0004-IND      Yes    nat-met-sto-tro        Natural    Meteorological   \n",
       "7  1924-0003-IND      Yes    nat-met-sto-tro        Natural    Meteorological   \n",
       "8  1925-0004-IND      Yes    nat-met-sto-tro        Natural    Meteorological   \n",
       "\n",
       "  Disaster Type  Disaster Subtype External IDs Event Name  ISO  ...  \\\n",
       "0       Drought           Drought          NaN        nan  IND  ...   \n",
       "1    Earthquake   Ground movement          NaN        nan  IND  ...   \n",
       "3         Storm  Tropical cyclone          NaN        nan  IND  ...   \n",
       "7         Storm  Tropical cyclone          NaN        nan  IND  ...   \n",
       "8         Storm  Tropical cyclone          NaN        nan  IND  ...   \n",
       "\n",
       "  Reconstruction Costs ('000 US$) Reconstruction Costs, Adjusted ('000 US$)  \\\n",
       "0                             NaN                                       NaN   \n",
       "1                             NaN                                       NaN   \n",
       "3                             NaN                                       NaN   \n",
       "7                             NaN                                       NaN   \n",
       "8                             NaN                                       NaN   \n",
       "\n",
       "  Insured Damage ('000 US$) Insured Damage, Adjusted ('000 US$)  \\\n",
       "0                       NaN                                 NaN   \n",
       "1                       NaN                                 NaN   \n",
       "3                       NaN                                 NaN   \n",
       "7                       NaN                                 NaN   \n",
       "8                       NaN                                 NaN   \n",
       "\n",
       "  Total Damage ('000 US$) Total Damage, Adjusted ('000 US$)       CPI  \\\n",
       "0                     NaN                               NaN  2.730451   \n",
       "1                 25000.0                          847777.0  2.948887   \n",
       "3                     NaN                               NaN  3.576717   \n",
       "7                     NaN                               NaN  5.611180   \n",
       "8                     NaN                               NaN  5.742436   \n",
       "\n",
       "  Admin Units  Entry Date  Last Update  \n",
       "0         NaN  2006-12-01   2023-09-25  \n",
       "1         NaN  2003-07-01   2023-09-25  \n",
       "3         NaN  2003-07-01   2023-09-25  \n",
       "7         NaN  2003-07-01   2023-09-25  \n",
       "8         NaN  2003-07-01   2023-09-25  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Exploring and Filtering Data ---\")\n",
    "print(\"\\nExploring Disaster Types:\")\n",
    "# Display more rows if needed: pd.set_option('display.max_rows', None)\n",
    "print(df_disasters['Disaster Type'].value_counts()) \n",
    "# pd.reset_option('display.max_rows')\n",
    "\n",
    "# Example: Filter for specific disaster types you want to focus on\n",
    "relevant_types = ['Flood', 'Storm', 'Drought', 'Wildfire', 'Earthquake','Extereme Temprature'] # Adjust this list\n",
    "df_filtered = df_disasters[df_disasters['Disaster Type'].isin(relevant_types)].copy() # Use .copy() to avoid warnings\n",
    "\n",
    "# Handle missing values in columns you'll use for prompts (fill with 'Unknown')\n",
    "# Adjust this list based on columns you actually use in create_training_example_from_csv_row\n",
    "cols_to_fill = ['Event Name', 'Disaster Group', 'Disaster Type', 'Disaster Subtype', 'Total Deaths', 'Total Damages']\n",
    "print(\"\\nHandling missing values (filling with 'Unknown')...\")\n",
    "for col in cols_to_fill:\n",
    "     if col in df_filtered.columns:\n",
    "          # Convert to string before filling NA to avoid type issues later\n",
    "          df_filtered[col] = df_filtered[col].astype(str).fillna('Unknown') \n",
    "     else:\n",
    "          print(f\"Warning: Column '{col}' not found in CSV during fillna.\")\n",
    "\n",
    "\n",
    "print(f\"\\nFiltered down to {len(df_filtered)} relevant events.\")\n",
    "if not df_filtered.empty:\n",
    "     print(\"\\nSample Filtered Data:\")\n",
    "     display(df_filtered.head())\n",
    "else:\n",
    "     print(\"Warning: Filtered DataFrame is empty. No examples will be generated from CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "044bbd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Example Creation Logic ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Defining Example Creation Logic ---\")\n",
    "\n",
    "def create_training_example_from_csv_row(row):\n",
    "    \"\"\"\n",
    "    Generates example training pairs (prompt/completion) from a CSV row.\n",
    "    Returns a LIST of examples, as one row might inspire multiple tasks.\n",
    "    Requires MANUAL WRITING of the 'output_text' completions.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    # --- Extract relevant info from the row ---\n",
    "    # Use .get() with default to handle potential missing columns gracefully\n",
    "    disaster_type = row.get('Disaster Type', 'Unknown Type')\n",
    "    location = row.get('Locationsort', 'Unknown Location')\n",
    "    start_date = row.get('Start Date', 'Unknown Date') \n",
    "    event_name = row.get('Event Names', 'Unnamed Event')\n",
    "    deaths = row.get('Total Deaths', 'N/A')\n",
    "    damage_usd = row.get('Total Damages', 'N/A') \n",
    "\n",
    "    # --- Task 1: Generate a Concise Event Summary ---\n",
    "    prompt_summary = f\"Based on historical records, provide a brief factual summary of this event:\\nEvent Type: {disaster_type}\\nLocation: {location}\\nStart Date: {start_date}\\nDetails: {event_name}\\nImpact: Deaths - {deaths}, Damage (USD Est.) - {damage_usd}\\n\\nSummary:\"\n",
    "    \n",
    "    # !!! Manual Completion Writing !!! \n",
    "    completion_summary = None # Default to None\n",
    "    # --- Start of your manual logic ---\n",
    "    if disaster_type == 'Flood' and 'Assam' in location and deaths != 'N/A':\n",
    "         completion_summary = f\"Historical record: Flooding impacted {location}, Assam, starting around {start_date}. The event resulted in {deaths} reported deaths and an estimated damage of {damage_usd} INR. So Kindly Take the necessary steps to protect yourself\"\n",
    "    elif disaster_type == 'Storm' and 'Odisha' in location and event_name != 'Unnamed Event':\n",
    "         completion_summary = f\"Historical record: The storm '{event_name}' affected {location}, Odisha, beginning {start_date}, causing {deaths} deaths and damage estimated at {damage_usd} INR.\"\n",
    "    elif disaster_type == 'Earthquake' and deaths != 'N/A':\n",
    "         completion_summary = f\"Historical record: An earthquake occurred in {location} starting {start_date}, described as '{event_name}'. It caused {deaths} deaths and estimated damages of {damage_usd} INR.\"\n",
    "    elif disaster_type == 'Landslide' and 'Himalayas' in location and event_name != 'Unnamed Event':\n",
    "         completion_summary = f\"Historical record: A landslide occurred in {location}, Himalayas, during {start_date}, described as '{event_name}'. It resulted in {deaths} deaths and damage estimated at {damage_usd} INR.\"\n",
    "    elif disaster_type == 'cylone' and 'Chennai' in location and event_name != 'Unnamed Event':\n",
    "         completion_summary = f\"Historical record: A Cyclone occurred in {location}, Chennai, around {start_date}, described as '{event_name}'. It resulted in {deaths} deaths and damage estimated at {damage_usd} INR. Check for other source for update of Cyclone and Take the necessary steps to protect yourself\"\n",
    "    elif disaster_type == 'Tsunami' and 'Kerala' in location and event_name != 'Unnamed Event':\n",
    "         completion_summary = f\"Historical record: A Tsunami occurred in {location}, Kerala, around {start_date}, described as '{event_name}'. It resulted in {deaths} deaths and damage estimated at {damage_usd} INR. Check for other source for update of Tsunami and Take the\"\n",
    "    else:\n",
    "         completion_summary = f\"Historical record: An event of type '{disaster_type}' occurred in {location}, around {start_date}, described as '{event_name}'. It resulted in {deaths} deaths and damage estimated at {damage_usd} INR. Check for other source for update of {disaster_type} and Take the necessary steps to protect yourself\"\n",
    "    # --- End of your manual logic ---\n",
    "    \n",
    "    if completion_summary:\n",
    "        examples.append({\"input_text\": prompt_summary, \"output_text\": completion_summary})\n",
    "    \n",
    "    # --- Task 2: Identify Likely Primary Impacts ---\n",
    "    prompt_impacts = f\"For a historical {disaster_type} event in {location}, list the likely primary impacts based on the disaster type.\"\n",
    "    \n",
    "    # !!! Manual Completion Writing !!!\n",
    "    completion_impacts = None\n",
    "    # --- Start of your manual logic ---\n",
    "    if disaster_type == 'Flood' and 'Assam' in location and deaths != 'N/A':\n",
    "         completion_impacts = f\"Historical record: Floods in {location}, Assam, impacted the following primary impacts: Flooded areas, Loss of life, Damage to infrastructure, Property damage, and displacement of people.\"\n",
    "    elif disaster_type == 'Storm' and 'Odisha' in location and event_name != 'Unnamed Event':\n",
    "         completion_impacts = f\"Historical record: The storm '{event_name}' impacted the following primary impacts: Storm damage, Loss of life, Property damage, Displacement of people, and Infrastructure damage.\"\n",
    "    elif disaster_type == 'Earthquake' and deaths != 'N/A':\n",
    "         completion_impacts = f\"Historical record: An earthquake occurred in {location} that impacted the following primary impacts: Earthquake damage, Loss of life, Property damage, and Infrastructure damage.\"\n",
    "    elif disaster_type == 'Landslide' and 'Himalayas' in location and event_name != 'Unnamed Event':\n",
    "         completion_impacts = f\"Historical record: A landslide occurred in {location}, Himalayas, that impacted the following primary impacts: Landslide damage, Loss of life, Property damage, and Infrastructure damage.\"\n",
    "    elif disaster_type == 'cylone' and 'Chennai' in location and event_name != 'Unnamed Event':\n",
    "         completion_impacts = f\"Historical record: A cyclone occurred in {location}, Chennai, that impacted the following primary impacts: Cyclone damage, Loss of life, Property damage, and Infrastructure damage.\"\n",
    "    elif disaster_type == 'Tsunami' and 'Kerala' in location and event_name != 'Unnamed Event':\n",
    "         completion_impacts = f\"Historical record: A tsunami occurred in {location}, Kerala, that impacted the following primary impacts: Tsunami damage, Loss of life, Property damage, and Infrastructure damage.\"\n",
    "    else:\n",
    "         completion_impacts = f\"Historical record: An event of type '{disaster_type}' occurred in {location}, that impacted the following primary impacts: {event_name} damage, Loss of life, Property damage, and Infrastructure damage.\"\n",
    "    # --- End of your manual logic ---\n",
    "    \n",
    "    if completion_impacts:\n",
    "        examples.append\n",
    "    # --- End of your manual logic ---\n",
    "    \n",
    "    if completion_summary:\n",
    "        examples.append({\"input_text\": prompt_summary, \"output_text\": completion_summary})\n",
    "    \n",
    "   # --- Task 2: Identify Likely Primary Impacts ---\n",
    "    prompt_impacts = f\"For a historical {disaster_type} event in {location}, list the likely primary impacts based on the disaster type.\"\n",
    "    \n",
    "    # !!! Manual Completion Writing !!!\n",
    "    completion_impacts = None\n",
    "    # --- Start of your manual logic ---\n",
    "    if disaster_type == 'Flood':\n",
    "        completion_impacts = \"Primary impacts likely included: displacement of people, damage to homes and infrastructure, loss of crops/livestock, potential water contamination, and disruption of transportation.\"\n",
    "    elif disaster_type == 'Storm':\n",
    "         completion_impacts = \"Primary impacts likely included: damage from high winds (trees, buildings, power lines), heavy rainfall causing localized flooding, possible storm surge if coastal, and disruption of essential services.\"\n",
    "    elif disaster_type == 'Earthquake':\n",
    "         completion_impacts = \"Primary impacts likely included: ground shaking causing structural damage or collapse, potential injuries/fatalities, landslides in hilly areas, disruption of utilities (water, power, gas), and possible aftershocks.\"\n",
    "    elif disaster_type == 'Landslide':\n",
    "         completion_impacts = \"Primary impacts likely included: burial of homes/infrastructure, blocking of roads/rivers, potential injuries/fatalities, and damage to the surrounding environment.\"\n",
    "    elif disaster_type == 'Drought':\n",
    "         completion_impacts = \"Primary impacts likely included: water scarcity (drinking, agriculture, industry), crop failure, livestock losses, increased wildfire risk, and potential economic hardship.\"\n",
    "    elif disaster_type == 'Extreme temperature': # Assume heatwave\n",
    "         completion_impacts = \"Primary impacts likely included: heat stress illnesses (heat exhaustion, heatstroke), increased mortality especially among vulnerable groups, strain on healthcare and power grids, and potential impact on agriculture/livestock.\"\n",
    "    # --- End of your manual logic ---\n",
    "    \n",
    "    if completion_impacts:\n",
    "        examples.append({\"input_text\": prompt_impacts, \"output_text\": completion_impacts})\n",
    "        \n",
    "        if disaster_type == 'Flood':\n",
    "             completion_impacts = \"Primary impacts likely included: displacement of people, damage to homes and infrastructure, loss of crops/livestock, potential water contamination, and disruption of transportation.\"\n",
    "        elif disaster_type == 'Storm':\n",
    "             completion_impacts = \"Primary impacts likely included: damage from high winds (trees, buildings, power lines), heavy rainfall causing localized flooding, possible storm surge if coastal, and disruption of essential services.\"\n",
    "        elif disaster_type == 'Earthquake':\n",
    "             completion_impacts = \"Primary impacts likely included: ground shaking causing structural damage or collapse, potential injuries/fatalities, landslides in hilly areas, disruption of utilities (water, power, gas), and possible aftershocks.\"\n",
    "        elif disaster_type == 'Landslide':\n",
    "             completion_impacts = \"Primary impacts likely included: burial of homes/infrastructure, blocking of roads/rivers, potential injuries/fatalities, and damage to the surrounding environment.\"\n",
    "        elif disaster_type == 'Drought':\n",
    "             completion_impacts = \"Primary impacts likely included: water scarcity (drinking, agriculture, industry), crop failure, livestock losses, increased wildfire risk, and potential economic hardship.\"\n",
    "        elif disaster_type == 'Extreme temperature': # Assume heatwave\n",
    "             completion_impacts = \"Primary impacts likely included: heat stress illnesses (heat exhaustion, heatstroke), increased mortality especially among vulnerable groups, strain on healthcare and power grids, and potential impact on agriculture/livestock.\"\n",
    "\n",
    "     \n",
    "    # --- End of your manual logic ---\n",
    "        \n",
    "    # --- Task 3: Suggest Preparedness Actions (Generic based on type) ---\n",
    "    # (Add prompt_prep and completion_prep logic here as in previous example if desired)\n",
    "    {\n",
    "         \"prompt\": \"What disaster occurred in Odisha in October 1999?\",\n",
    "         \"completion\": \"A massive cyclone hit Odisha in October 1999, causing over $4.5 billion in damages.\" \n",
    "      }\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1f8d4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Examples from CSV Data ---\n",
      "Processed 100/586 rows...\n",
      "Processed 200/586 rows...\n",
      "Processed 300/586 rows...\n",
      "Processed 400/586 rows...\n",
      "Processed 500/586 rows...\n",
      "Finished processing CSV. Generated 1754 examples from 586 CSV rows.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Generating Examples from CSV Data ---\")\n",
    "all_examples = []\n",
    "if not df_filtered.empty:\n",
    "    # Limit processing for testing? Uncomment below:\n",
    "    # sample_df = df_filtered.sample(n=min(200, len(df_filtered)), random_state=42) \n",
    "    sample_df = df_filtered # Process all filtered rows\n",
    "    \n",
    "    processed_rows = 0\n",
    "    for index, row in sample_df.iterrows():\n",
    "        generated = create_training_example_from_csv_row(row)\n",
    "        all_examples.extend(generated) \n",
    "        processed_rows += 1\n",
    "        if processed_rows % 100 == 0: # Print progress\n",
    "             print(f\"Processed {processed_rows}/{len(sample_df)} rows...\")\n",
    "             \n",
    "    print(f\"Finished processing CSV. Generated {len(all_examples)} examples from {len(sample_df)} CSV rows.\")\n",
    "else:\n",
    "    print(\"Filtered DataFrame is empty, cannot generate examples from CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5aa4d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Adding Manually Created Examples ---\n",
      "Added 4 manual examples.\n",
      "Total examples for fine-tuning: 1758\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Adding Manually Created Examples ---\")\n",
    "# Add examples that are NOT derived from the CSV, like summarizing actual weather reports\n",
    "# or generating alerts based on hypothetical scenarios.\n",
    "manual_examples = [\n",
    "    {\"input_text\": \"Summarize this forecast: Mumbai - Max Temp 34C, Min Temp 28C. Humidity 85%. Heavy rainfall warning issued for the next 24 hours due to active monsoon conditions. Possibility of waterlogging in low-lying areas.\", \n",
    "     \"output_text\": \"Heavy Rain Alert for Mumbai: Expect heavy rainfall over the next 24 hours with high humidity (85%) and temperatures between 28-34C. Risk of waterlogging in low-lying areas. Take necessary precautions.\"},\n",
    "    {\"input_text\": \"Generate a public safety message for the following heatwave warning: Delhi - Temperatures expected to reach 45-47C for the next 3 days. IMD advises avoiding direct sun exposure between 11 AM and 4 PM.\", \n",
    "     \"output_text\": \"Public Safety Advisory - Heatwave in Delhi: Extreme heat predicted for the next 3 days (45-47C). Avoid sun exposure between 11 AM - 4 PM. Stay hydrated, wear light clothing, and check on vulnerable individuals.\"},\n",
    "    {\"input_text\": \"Context:\\n- Current Weather: Heavy rain warning in Chennai, possibility of urban flooding.\\n- News: Waterlogging reported in T. Nagar and Velachery.\\nUser Query: Is it safe to travel across the city?\",\n",
    "     \"output_text\": \"Travel Advisory for Chennai: Due to heavy rain warnings and reported waterlogging in areas like T. Nagar and Velachery, non-essential travel across the city is discouraged. Check official traffic updates and avoid flooded streets.\"},\n",
    "    {\"input_text\": \"What are the safety steps during an earthquake?\",\n",
    "     \"output_text\": \"During an earthquake: DROP to the ground, take COVER under a sturdy table or desk, and HOLD ON until the shaking stops. Stay away from windows, outer walls, and anything that could fall. If outdoors, move to an open area away from buildings and power lines.\"},\n",
    "    # --- !!! ADD MANY MORE (Aim for 100+ initially) HIGH-QUALITY MANUAL EXAMPLES !!! ---\n",
    "    # Cover different disaster types, locations, and tasks (summarize, risks, safety steps, Q&A)\n",
    "]\n",
    "all_examples.extend(manual_examples)\n",
    "print(f\"Added {len(manual_examples)} manual examples.\")\n",
    "print(f\"Total examples for fine-tuning: {len(all_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f32244af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Splitting and Saving Data ---\n",
      "Final Training set size: 1583\n",
      "Final Validation set size: 175\n",
      "1583 examples successfully saved to data\\train.jsonl\n",
      "175 examples successfully saved to data\\validation.jsonl\n",
      "\n",
      "Sample Training Data Entries (First 3):\n",
      "{\n",
      "  \"input_text\": \"Based on historical records, provide a brief factual summary of this event:\\nEvent Type: Flood\\nLocation: Unknown Location\\nStart Date: Unknown Date\\nDetails: Unnamed Event\\nImpact: Deaths - 133.0, Damage (USD Est.) - N/A\\n\\nSummary:\",\n",
      "  \"output_text\": \"Historical record: An event of type 'Flood' occurred in Unknown Location, around Unknown Date, described as 'Unnamed Event'. It resulted in 133.0 deaths and damage estimated at N/A INR. Check for other source for update of Flood and Take the necessary steps to protect yourself\"\n",
      "}\n",
      "{\n",
      "  \"input_text\": \"For a historical Storm event in Unknown Location, list the likely primary impacts based on the disaster type.\",\n",
      "  \"output_text\": \"Primary impacts likely included: damage from high winds (trees, buildings, power lines), heavy rainfall causing localized flooding, possible storm surge if coastal, and disruption of essential services.\"\n",
      "}\n",
      "{\n",
      "  \"input_text\": \"For a historical Storm event in Unknown Location, list the likely primary impacts based on the disaster type.\",\n",
      "  \"output_text\": \"Primary impacts likely included: damage from high winds (trees, buildings, power lines), heavy rainfall causing localized flooding, possible storm surge if coastal, and disruption of essential services.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Splitting and Saving Data ---\")\n",
    "if all_examples:\n",
    "    # Shuffle the data thoroughly before splitting\n",
    "    random.seed(42) # for reproducible splits\n",
    "    random.shuffle(all_examples)\n",
    "    \n",
    "    # Split data (e.g., 90% train, 10% validation)\n",
    "    # Ensure there's at least 1 validation example if the dataset is tiny\n",
    "    num_validation = max(1, int(len(all_examples) * 0.1)) \n",
    "    if len(all_examples) - num_validation <= 0: # Handle very small datasets\n",
    "         print(\"Warning: Dataset too small for validation split. Using all for training.\")\n",
    "         train_data = all_examples\n",
    "         validation_data = []\n",
    "    else:\n",
    "         validation_data = all_examples[:num_validation]\n",
    "         train_data = all_examples[num_validation:]\n",
    "\n",
    "    print(f\"Final Training set size: {len(train_data)}\")\n",
    "    print(f\"Final Validation set size: {len(validation_data)}\")\n",
    "\n",
    "    # Function to save data to JSONL\n",
    "    def save_to_jsonl(data, filename):\n",
    "        count = 0\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                for item in data:\n",
    "                    # Ensure item is a dictionary before dumping\n",
    "                    if isinstance(item, dict) and \"input_text\" in item and \"output_text\" in item:\n",
    "                         f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "                         count += 1\n",
    "                    else:\n",
    "                         print(f\"Warning: Skipping invalid item during save (must be dict with keys): {item}\")\n",
    "            print(f\"{count} examples successfully saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR saving file {filename}: {e}\")\n",
    "\n",
    "    # Save the files\n",
    "    if train_data:\n",
    "        save_to_jsonl(train_data, OUTPUT_TRAIN_FILE)\n",
    "    if validation_data:\n",
    "        save_to_jsonl(validation_data, OUTPUT_VALID_FILE)\n",
    "    \n",
    "    # Display some final examples (optional)\n",
    "    print(\"\\nSample Training Data Entries (First 3):\")\n",
    "    for i in range(min(3, len(train_data))):\n",
    "        if isinstance(train_data[i], dict):\n",
    "             print(json.dumps(train_data[i], indent=2, ensure_ascii=False))\n",
    "        \n",
    "else:\n",
    "    print(\"\\nNo training examples were generated or added. Cannot save JSONL files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df6f26a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Notebook Complete ---\n",
      "Review the generated files in the 'data' folder:\n",
      "- train.jsonl\n",
      "- validation.jsonl\n",
      "\n",
      "Ensure the format (one JSON per line with 'input_text' and 'output_text') is correct for Vertex AI tuning.\n",
      "Next steps for fine-tuning Gemini:\n",
      "1. Create a Google Cloud Project and enable Vertex AI API.\n",
      "2. Create a Google Cloud Storage (GCS) bucket.\n",
      "3. Upload 'train.jsonl' (and optionally validation file) to the GCS bucket.\n",
      "4. Go to Vertex AI in the Google Cloud Console -> Model Garden or Generative AI Studio.\n",
      "5. Find a tunable base model (e.g., 'gemini-1.0-pro-002' - check availability).\n",
      "6. Start a tuning job, pointing it to your data on GCS.\n",
      "7. After tuning, deploy the tuned model to a Vertex AI Endpoint.\n",
      "8. Update your backend API code to call the Vertex AI Endpoint instead of the base Gemini model.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Notebook Complete ---\")\n",
    "print(f\"Review the generated files in the '{DATA_DIR}' folder:\")\n",
    "print(f\"- {os.path.basename(OUTPUT_TRAIN_FILE)}\")\n",
    "print(f\"- {os.path.basename(OUTPUT_VALID_FILE)}\")\n",
    "print(\"\\nEnsure the format (one JSON per line with 'input_text' and 'output_text') is correct for Vertex AI tuning.\")\n",
    "print(\"Next steps for fine-tuning Gemini:\")\n",
    "print(\"1. Create a Google Cloud Project and enable Vertex AI API.\")\n",
    "print(f\"2. Create a Google Cloud Storage (GCS) bucket.\")\n",
    "print(f\"3. Upload '{os.path.basename(OUTPUT_TRAIN_FILE)}' (and optionally validation file) to the GCS bucket.\")\n",
    "print(\"4. Go to Vertex AI in the Google Cloud Console -> Model Garden or Generative AI Studio.\")\n",
    "print(\"5. Find a tunable base model (e.g., 'gemini-1.0-pro-002' - check availability).\")\n",
    "print(\"6. Start a tuning job, pointing it to your data on GCS.\")\n",
    "print(\"7. After tuning, deploy the tuned model to a Vertex AI Endpoint.\")\n",
    "print(\"8. Update your backend API code to call the Vertex AI Endpoint instead of the base Gemini model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dab3b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\ai model\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in d:\\ai model\\.venv\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\ai model\\.venv\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai model\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai model\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai model\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in d:\\ai model\\.venv\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai model\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea12cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output training data will be saved to: data\\train.jsonl\n",
      "Output validation data will be saved to: data\\validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "# Define paths\n",
    "DATA_DIR = \"data\"\n",
    "OUTPUT_TRAIN_FILE = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "OUTPUT_VALID_FILE = os.path.join(DATA_DIR, \"validation.jsonl\")\n",
    "# Path to any raw data you might load (e.g., downloaded CSVs, PDF folder)\n",
    "RAW_DATA_PATH = os.path.join(DATA_DIR, \"raw\") \n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RAW_DATA_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Output training data will be saved to: {OUTPUT_TRAIN_FILE}\")\n",
    "print(f\"Output validation data will be saved to: {OUTPUT_VALID_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8558eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 raw text snippets (example).\n"
     ]
    }
   ],
   "source": [
    "raw_texts = [\n",
    "    \"IMD Bulletin: Heavy rainfall warning for coastal Kerala for next 48 hours. Fishermen advised not to venture into sea. Strong winds likely.\",\n",
    "    \"USGS Report: Magnitude 4.8 earthquake recorded 50km NE of Shimla, Himachal Pradesh. Depth 10km. No immediate damage reports.\",\n",
    "    \"News Headline: Flash floods trigger landslides in Uttarakhand, several roads blocked. Rescue operations underway.\",\n",
    "    \"Forecast Discussion: Monsoon trough active over central India. Expect widespread moderate rainfall with isolated heavy spells over MP and Maharashtra.\",\n",
    "    \"Heatwave conditions persist over Rajasthan and Gujarat, with temperatures exceeding 45C in many places. Avoid sun exposure.\"\n",
    "]\n",
    "print(f\"Loaded {len(raw_texts)} raw text snippets (example).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ee7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gemini_tuning_example(raw_text, task_type=\"summarize\"):\n",
    "    \"\"\"Creates a prompt/completion pair for Gemini fine-tuning.\"\"\"\n",
    "    \n",
    "    if task_type == \"summarize\":\n",
    "        prompt = f\"Summarize the key information from this report concisely for a public alert:\\n\\nReport:\\n{raw_text}\\n\\nSummary:\"\n",
    "        # --- !!! MANUALLY WRITE THE IDEAL SUMMARY HERE based on raw_text !!! ---\n",
    "        if \"Kerala\" in raw_text:\n",
    "             completion = \"Heavy Rain & Wind Warning: Coastal Kerala expects heavy rain & strong winds for 48 hrs. Fishermen advised stay ashore.\"\n",
    "        elif \"Shimla\" in raw_text:\n",
    "             completion = \"Earthquake Update: Magnitude 4.8 quake hit near Shimla, HP (Depth 10km). No immediate damage reported. Monitor updates.\"\n",
    "        elif \"Uttarakhand\" in raw_text:\n",
    "             completion = \"Flood & Landslide Alert: Flash floods & landslides block roads in Uttarakhand. Rescue ops ongoing. Avoid affected areas.\"\n",
    "        elif \"Monsoon trough\" in raw_text:\n",
    "             completion = \"Monsoon Rain Forecast: Widespread moderate rain, with isolated heavy spells, expected over Madhya Pradesh & Maharashtra due to active monsoon trough.\"\n",
    "        elif \"Heatwave\" in raw_text:\n",
    "             completion = \"Heatwave Warning: Persistent heatwave in Rajasthan & Gujarat (>45C). Avoid sun exposure, stay hydrated.\"\n",
    "        else:\n",
    "             completion = \"Summary not available for this example.\" # Placeholder\n",
    "             \n",
    "    elif task_type == \"identify_risks\":\n",
    "        prompt = f\"Identify the main risks mentioned or implied in this report:\\n\\nReport:\\n{raw_text}\\n\\nRisks:\"\n",
    "        # --- !!! MANUALLY WRITE THE IDEAL RISK LIST HERE based on raw_text !!! ---\n",
    "        if \"Kerala\" in raw_text:\n",
    "             completion = \"- Flooding due to heavy rain\\n- Damage from strong winds\\n- Danger to fishermen at sea\"\n",
    "        elif \"Shimla\" in raw_text:\n",
    "             completion = \"- Potential aftershocks\\n- Possible minor structural damage (though none reported yet)\"\n",
    "        elif \"Uttarakhand\" in raw_text:\n",
    "             completion = \"- Danger from flash floods\\n- Risk of being trapped due to landslides/road blockages\"\n",
    "        # ... add more completions for other examples ...\n",
    "        else:\n",
    "             completion = \"Risk identification not available for this example.\"\n",
    "\n",
    "    # Add more task types as needed (e.g., 'generate_alert_tweet', 'answer_faq')\n",
    "    \n",
    "    else: # Default or unknown task\n",
    "        return None\n",
    "\n",
    "    # Return in the format needed for Vertex AI tuning (check docs)\n",
    "    return {\"input_text\": prompt, \"output_text\": completion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429bb040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 training examples.\n",
      "Generated 4 training examples.\n",
      "Generated 6 training examples.\n",
      "Generated 7 training examples.\n",
      "Generated 8 training examples.\n",
      "\n",
      "Sample Example:\n",
      "{\n",
      "  \"input_text\": \"Summarize the key information from this report concisely for a public alert:\\n\\nReport:\\nIMD Bulletin: Heavy rainfall warning for coastal Kerala for next 48 hours. Fishermen advised not to venture into sea. Strong winds likely.\\n\\nSummary:\",\n",
      "  \"output_text\": \"Heavy Rain & Wind Warning: Coastal Kerala expects heavy rain & strong winds for 48 hrs. Fishermen advised stay ashore.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "training_examples = []\n",
    "for text in raw_texts:\n",
    "    # Create different types of examples from the same raw text\n",
    "    summary_example = create_gemini_tuning_example(text, task_type=\"summarize\")\n",
    "    risk_example = create_gemini_tuning_example(text, task_type=\"identify_risks\")\n",
    "    \n",
    "    if summary_example and summary_example[\"output_text\"] != \"Summary not available for this example.\":\n",
    "        training_examples.append(summary_example)\n",
    "    if risk_example and risk_example[\"output_text\"] != \"Risk identification not available for this example.\":\n",
    "         training_examples.append(risk_example)\n",
    "\n",
    "    print(f\"Generated {len(training_examples)} training examples.\")\n",
    "if training_examples:\n",
    "    print(\"\\nSample Example:\")\n",
    "    print(json.dumps(training_examples[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41bf8468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 6\n",
      "Validation set size: 2\n",
      "\n",
      "Training data saved to data\\train.jsonl\n",
      "Validation data saved to data\\validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "if training_examples:\n",
    "    df = pd.DataFrame(training_examples)\n",
    "    \n",
    "    # Simple split for demo: 80% train, 20% validation\n",
    "    validation_df = df.sample(frac=0.2, random_state=42) # Use frac=0.2 for 20% validation\n",
    "    train_df = df.drop(validation_df.index)\n",
    "\n",
    "    print(f\"\\nTraining set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(validation_df)}\")\n",
    "\n",
    "    # Save to JSONL format (one JSON object per line)\n",
    "    train_df.to_json(OUTPUT_TRAIN_FILE, orient='records', lines=True)\n",
    "    validation_df.to_json(OUTPUT_VALID_FILE, orient='records', lines=True)\n",
    "\n",
    "    print(f\"\\nTraining data saved to {OUTPUT_TRAIN_FILE}\")\n",
    "    print(f\"Validation data saved to {OUTPUT_VALID_FILE}\")\n",
    "else:\n",
    "    print(\"\\nNo training examples generated, skipping save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
